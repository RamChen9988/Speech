import numpy as np
import matplotlib.pyplot as plt
import librosa
import librosa.display
import sounddevice as sd
import soundfile as sf
from scipy import signal
import os
import requests
import tempfile
import IPython.display as ipd
from urllib.parse import urlparse
import warnings
warnings.filterwarnings('ignore')

class AudioProcessingDemo:
    def __init__(self, sample_rate=22050):
        self.sample_rate = sample_rate
        self.original_audio = None
        self.processed_audio = None
        self.audio_duration = 0
        
    def download_audio_from_url(self, url, max_duration=10):
        """ä»URLä¸‹è½½éŸ³é¢‘æ–‡ä»¶"""
        try:
            print(f"æ­£åœ¨ä»URLä¸‹è½½éŸ³é¢‘: {url}")
            
            # åˆ›å»ºä¸‹è½½ç›®å½•
            download_dir = "downloaded_audio"
            if not os.path.exists(download_dir):
                os.makedirs(download_dir)
            
            parsed_url = urlparse(url)
            filename = os.path.basename(parsed_url.path) or "downloaded_audio.wav"
            download_path = os.path.join(download_dir, filename)
            
            # ä¸‹è½½æ–‡ä»¶
            response = requests.get(url, stream=True, timeout=30)
            response.raise_for_status()
            
            with open(download_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
            
            print(f"éŸ³é¢‘ä¸‹è½½å®Œæˆï¼Œä¿å­˜åˆ°: {download_path}")
            
            # åŠ è½½éŸ³é¢‘
            audio, sr = librosa.load(download_path, sr=self.sample_rate, duration=max_duration)
            self.original_audio = audio
            self.sample_rate = sr
            self.audio_duration = len(audio) / sr
            
            print(f"éŸ³é¢‘åŠ è½½æˆåŠŸ: {self.audio_duration:.2f}ç§’, é‡‡æ ·ç‡: {self.sample_rate}Hz")
            
            return audio
            
        except Exception as e:
            print(f"ä¸‹è½½éŸ³é¢‘å¤±è´¥: {e}")
            print("ä½¿ç”¨å†…ç½®ç¤ºä¾‹éŸ³é¢‘...")
            return self.load_example_audio()
    
    def load_example_audio(self):
        """åŠ è½½å†…ç½®ç¤ºä¾‹éŸ³é¢‘"""
        try:
            # ä½¿ç”¨librosaè‡ªå¸¦çš„ç¤ºä¾‹éŸ³é¢‘
            file_path = librosa.example('trumpet')
            self.original_audio, self.sample_rate = librosa.load(file_path, sr=self.sample_rate)
            self.audio_duration = len(self.original_audio) / self.sample_rate
            print(f"åŠ è½½ç¤ºä¾‹éŸ³é¢‘æˆåŠŸ: {self.audio_duration:.2f}ç§’")
            return self.original_audio
        except Exception as e:
            print(f"åŠ è½½ç¤ºä¾‹éŸ³é¢‘å¤±è´¥: {e}")
            # ç”Ÿæˆæµ‹è¯•éŸ³é¢‘
            return self.generate_test_audio()
    
    def generate_test_audio(self):
        """ç”Ÿæˆæµ‹è¯•éŸ³é¢‘"""
        duration = 3  # 3ç§’
        t = np.linspace(0, duration, int(duration * self.sample_rate))
        
        # ç”ŸæˆåŒ…å«å¤šä¸ªé¢‘ç‡çš„å¤æ‚ä¿¡å·
        # åŸºé¢‘ + è°æ³¢ + å™ªå£°
        base_freq = 220  # A3
        self.original_audio = (
            0.7 * np.sin(2 * np.pi * base_freq * t) +           # åŸºé¢‘
            0.3 * np.sin(2 * np.pi * base_freq * 2 * t) +       # äºŒæ¬¡è°æ³¢
            0.2 * np.sin(2 * np.pi * base_freq * 3 * t) +       # ä¸‰æ¬¡è°æ³¢
            0.1 * np.random.randn(len(t))                       # å™ªå£°
        )
        self.original_audio = self.original_audio.astype(np.float32)
        self.audio_duration = duration
        
        print("ç”Ÿæˆæµ‹è¯•éŸ³é¢‘æˆåŠŸ")
        return self.original_audio
    
    def record_audio(self, duration=5):
        """å½•åˆ¶éŸ³é¢‘"""
        print(f"å¼€å§‹å½•éŸ³ï¼Œè¯·è¯´è¯... ({duration}ç§’)")
        audio_data = sd.rec(int(duration * self.sample_rate), 
                           samplerate=self.sample_rate, 
                           channels=1)
        sd.wait()
        self.original_audio = audio_data.flatten()
        self.audio_duration = duration
        print("å½•éŸ³å®Œæˆ!")
        return self.original_audio
    
    def apply_pitch_shift(self, audio, n_steps=4):
        """éŸ³é«˜å˜æ¢ï¼ˆäº§ç”Ÿæ˜æ˜¾å¬è§‰å·®å¼‚ï¼‰"""
        print(f"åº”ç”¨éŸ³é«˜å˜æ¢: {n_steps} ä¸ªåŠéŸ³")
        return librosa.effects.pitch_shift(audio, sr=self.sample_rate, n_steps=n_steps)
    
    def apply_time_stretch(self, audio, rate=1.5):
        """æ—¶é—´æ‹‰ä¼¸ï¼ˆäº§ç”Ÿæ˜æ˜¾å¬è§‰å·®å¼‚ï¼‰"""
        print(f"åº”ç”¨æ—¶é—´æ‹‰ä¼¸: {rate}x é€Ÿåº¦")
        return librosa.effects.time_stretch(audio, rate=rate)
    
    def apply_reverb(self, audio, delay=0.1, decay=0.5):
        """æ·»åŠ æ··å“æ•ˆæœ"""
        print("æ·»åŠ æ··å“æ•ˆæœ")
        # ç®€å•çš„æ··å“å®ç°
        delayed = np.zeros_like(audio)
        delay_samples = int(delay * self.sample_rate)
        
        if delay_samples < len(audio):
            delayed[delay_samples:] = audio[:-delay_samples] * decay
        
        return audio + delayed
    
    def apply_lowpass_filter(self, audio, cutoff_freq=1000):
        """åº”ç”¨ä½é€šæ»¤æ³¢å™¨ï¼ˆè®©å£°éŸ³å˜é—·ï¼‰"""
        print(f"åº”ç”¨ä½é€šæ»¤æ³¢å™¨: æˆªæ­¢é¢‘ç‡ {cutoff_freq}Hz")
        nyquist = self.sample_rate / 2
        normal_cutoff = cutoff_freq / nyquist
        b, a = signal.butter(4, normal_cutoff, btype='low', analog=False)
        return signal.filtfilt(b, a, audio)
    
    def apply_highpass_filter(self, audio, cutoff_freq=2000):
        """åº”ç”¨é«˜é€šæ»¤æ³¢å™¨ï¼ˆè®©å£°éŸ³å˜å°–ï¼‰"""
        print(f"åº”ç”¨é«˜é€šæ»¤æ³¢å™¨: æˆªæ­¢é¢‘ç‡ {cutoff_freq}Hz")
        nyquist = self.sample_rate / 2
        normal_cutoff = cutoff_freq / nyquist
        b, a = signal.butter(4, normal_cutoff, btype='high', analog=False)
        return signal.filtfilt(b, a, audio)
    
    def apply_distortion(self, audio, gain=5.0):
        """åº”ç”¨å¤±çœŸæ•ˆæœ"""
        print("åº”ç”¨å¤±çœŸæ•ˆæœ")
        # ç®€å•çš„è½¯å‰Šæ³¢å¤±çœŸ
        distorted = np.tanh(gain * audio)
        return distorted / np.max(np.abs(distorted))
    
    def add_noise(self, audio, noise_level=0.1):
        """æ·»åŠ å™ªå£°ï¼ˆç”¨äºåˆ›å»ºå¸¦å™ªè¯­éŸ³ï¼‰"""
        print(f"æ·»åŠ å™ªå£°ï¼Œå™ªå£°æ°´å¹³: {noise_level}")
        noise = noise_level * np.random.randn(len(audio))
        return audio + noise
    
    def apply_noise_reduction(self, audio, reduction_strength=0.8):
        """åº”ç”¨å™ªå£°æŠ‘åˆ¶ï¼ˆè°±å‡æ³•ï¼‰"""
        print(f"åº”ç”¨å™ªå£°æŠ‘åˆ¶ï¼Œå¼ºåº¦: {reduction_strength}")
        
        # ä½¿ç”¨è°±å‡æ³•è¿›è¡Œå™ªå£°æŠ‘åˆ¶
        stft = librosa.stft(audio)
        magnitude = np.abs(stft)
        phase = np.angle(stft)
        
        # ä¼°è®¡å™ªå£°è°±ï¼ˆä½¿ç”¨å‰å‡ å¸§ï¼‰
        noise_frames = 10
        noise_magnitude = np.mean(magnitude[:, :noise_frames], axis=1, keepdims=True)
        
        # è°±å‡æ³•
        enhanced_magnitude = magnitude - reduction_strength * noise_magnitude
        enhanced_magnitude = np.maximum(enhanced_magnitude, 0.01 * magnitude)  # é¿å…è´Ÿå€¼
        
        # é‡å»ºä¿¡å·
        enhanced_stft = enhanced_magnitude * np.exp(1j * phase)
        enhanced_audio = librosa.istft(enhanced_stft)
        
        return enhanced_audio
    
    def apply_voice_enhancement(self, audio, enhancement_factor=1.5):
        """åº”ç”¨è¯­éŸ³å¢å¼ºï¼ˆæå‡è¯­éŸ³é¢‘ç‡ï¼‰"""
        print(f"åº”ç”¨è¯­éŸ³å¢å¼ºï¼Œå¢å¼ºå› å­: {enhancement_factor}")
        
        # ä½¿ç”¨å¸¦é€šæ»¤æ³¢å™¨å¢å¼ºè¯­éŸ³é¢‘ç‡èŒƒå›´ï¼ˆ300-3400Hzï¼‰
        nyquist = self.sample_rate / 2
        low_freq = 300 / nyquist
        high_freq = 3400 / nyquist
        
        # è®¾è®¡å¸¦é€šæ»¤æ³¢å™¨
        b, a = signal.butter(4, [low_freq, high_freq], btype='band')
        filtered_audio = signal.filtfilt(b, a, audio)
        
        # å¢å¼ºè¯­éŸ³é¢‘æ®µ
        enhanced_audio = audio + (enhancement_factor - 1) * filtered_audio
        
        # å½’ä¸€åŒ–
        enhanced_audio = enhanced_audio / np.max(np.abs(enhanced_audio)) * np.max(np.abs(audio))
        
        return enhanced_audio
    
    def apply_compression(self, audio, threshold=0.5, ratio=4.0):
        """åº”ç”¨åŠ¨æ€å‹ç¼©"""
        print(f"åº”ç”¨åŠ¨æ€å‹ç¼©ï¼Œé˜ˆå€¼: {threshold}, å‹ç¼©æ¯”: {ratio}:1")
        
        # ç®€å•çš„åŠ¨æ€å‹ç¼©å®ç°
        compressed = np.copy(audio)
        
        # å¯¹è¶…è¿‡é˜ˆå€¼çš„éƒ¨åˆ†è¿›è¡Œå‹ç¼©
        mask = np.abs(audio) > threshold
        compressed[mask] = threshold + (audio[mask] - threshold) / ratio
        
        return compressed
    
    def create_dramatic_effect(self, audio):
        """åˆ›å»ºæˆå‰§æ€§çš„å¬è§‰å˜åŒ–æ•ˆæœ"""
        print("åˆ›å»ºæˆå‰§æ€§å¬è§‰å˜åŒ–æ•ˆæœ...")
        
        # ç»„åˆå¤šç§æ•ˆæœ
        # 1. å…ˆå˜è°ƒï¼ˆæé«˜éŸ³é«˜ï¼‰
        processed = self.apply_pitch_shift(audio, n_steps=6)
        
        # 2. åŠ é€Ÿæ’­æ”¾
        processed = self.apply_time_stretch(processed, rate=1.8)
        
        # 3. æ·»åŠ å¤±çœŸ
        processed = self.apply_distortion(processed, gain=8.0)
        
        # 4. æ·»åŠ æ··å“
        processed = self.apply_reverb(processed, delay=0.15, decay=0.7)
        
        return processed
    
    def create_noise_cleaning_effect(self, audio):
        """åˆ›å»ºå™ªå£°æ¸…ç†å’Œè¯­éŸ³å¢å¼ºæ•ˆæœ"""
        print("åˆ›å»ºå™ªå£°æ¸…ç†å’Œè¯­éŸ³å¢å¼ºæ•ˆæœ...")
        
        # 1. å…ˆæ·»åŠ å™ªå£°ï¼ˆæ¨¡æ‹Ÿå˜ˆæ‚ç¯å¢ƒï¼‰
        noisy_audio = self.add_noise(audio, noise_level=0.15)
        
        # 2. åº”ç”¨å™ªå£°æŠ‘åˆ¶
        cleaned_audio = self.apply_noise_reduction(noisy_audio, reduction_strength=0.7)
        
        # 3. åº”ç”¨è¯­éŸ³å¢å¼º
        enhanced_audio = self.apply_voice_enhancement(cleaned_audio, enhancement_factor=1.8)
        
        # 4. åº”ç”¨åŠ¨æ€å‹ç¼©
        final_audio = self.apply_compression(enhanced_audio, threshold=0.3, ratio=3.0)
        
        return final_audio, noisy_audio
    
    def demonstrate_noise_cleaning(self):
        """æ¼”ç¤ºå™ªå£°æ¸…ç†æ•ˆæœ"""
        if self.original_audio is None:
            print("è¯·å…ˆåŠ è½½éŸ³é¢‘!")
            return
        
        print("\n" + "="*50)
        print("å™ªå£°æ¸…ç†å’Œè¯­éŸ³å¢å¼ºæ¼”ç¤º")
        print("="*50)
        
        # åˆ›å»ºå¸¦å™ªè¯­éŸ³å¹¶æ¸…ç†
        enhanced_audio, noisy_audio = self.create_noise_cleaning_effect(self.original_audio)
        self.processed_audio = enhanced_audio
        
        # ä¿å­˜å¸¦å™ªéŸ³é¢‘ç”¨äºå¯¹æ¯”
        self.noisy_audio = noisy_audio
        
        print("\nğŸµ æ’­æ”¾åŸå§‹éŸ³é¢‘...")
        ipd.display(ipd.Audio(self.original_audio, rate=self.sample_rate))
        
        print("ğŸµ æ’­æ”¾å¸¦å™ªéŸ³é¢‘ï¼ˆæ¨¡æ‹Ÿå˜ˆæ‚ç¯å¢ƒï¼‰...")
        ipd.display(ipd.Audio(self.noisy_audio, rate=self.sample_rate))
        
        print("ğŸµ æ’­æ”¾æ¸…ç†åçš„éŸ³é¢‘...")
        ipd.display(ipd.Audio(self.processed_audio, rate=self.sample_rate))
        
        # åˆ†ææ•ˆæœ
        self.analyze_noise_cleaning_effect()
        
        # æ˜¾ç¤ºå¯¹æ¯”å›¾è¡¨
        self.plot_noise_cleaning_comparison()
        
        # ä¿å­˜é€‰é¡¹
        save_choice = input("\næ˜¯å¦ä¿å­˜éŸ³é¢‘æ–‡ä»¶? (y/n): ").strip().lower()
        if save_choice == 'y':
            self.save_noise_cleaning_files()
        
        print("\nå™ªå£°æ¸…ç†æ¼”ç¤ºå®Œæˆ!")
    
    def analyze_noise_cleaning_effect(self):
        """åˆ†æå™ªå£°æ¸…ç†æ•ˆæœ"""
        # ç¡®ä¿éŸ³é¢‘é•¿åº¦ä¸€è‡´ï¼ˆæˆªå–åˆ°æœ€çŸ­é•¿åº¦ï¼‰
        min_length = min(len(self.original_audio), len(self.noisy_audio), len(self.processed_audio))
        orig_audio = self.original_audio[:min_length]
        noisy_audio = self.noisy_audio[:min_length]
        clean_audio = self.processed_audio[:min_length]
        
        orig_rms = np.sqrt(np.mean(orig_audio**2))
        noisy_rms = np.sqrt(np.mean(noisy_audio**2))
        clean_rms = np.sqrt(np.mean(clean_audio**2))
        
        # è®¡ç®—ä¿¡å™ªæ¯”æ”¹è¿›
        noise_power = np.mean((noisy_audio - orig_audio)**2)
        signal_power = np.mean(orig_audio**2)
        original_snr = 10 * np.log10(signal_power / noise_power) if noise_power > 0 else float('inf')
        
        clean_noise_power = np.mean((clean_audio - orig_audio)**2)
        clean_snr = 10 * np.log10(signal_power / clean_noise_power) if clean_noise_power > 0 else float('inf')
        
        print(f"\nğŸ¯ å™ªå£°æ¸…ç†æ•ˆæœåˆ†æ:")
        print(f"åŸå§‹éŸ³é¢‘ RMS: {orig_rms:.4f}")
        print(f"å¸¦å™ªéŸ³é¢‘ RMS: {noisy_rms:.4f} (+{((noisy_rms/orig_rms)-1)*100:.1f}%)")
        print(f"æ¸…ç†åéŸ³é¢‘ RMS: {clean_rms:.4f} (+{((clean_rms/orig_rms)-1)*100:.1f}%)")
        
        if original_snr != float('inf'):
            print(f"å¸¦å™ªéŸ³é¢‘ä¿¡å™ªæ¯”: {original_snr:.1f} dB")
            print(f"æ¸…ç†åéŸ³é¢‘ä¿¡å™ªæ¯”: {clean_snr:.1f} dB")
            print(f"ä¿¡å™ªæ¯”æ”¹è¿›: {clean_snr - original_snr:.1f} dB")
        
        # é¢‘è°±è´¨å¿ƒå¯¹æ¯”
        orig_centroid = librosa.feature.spectral_centroid(y=orig_audio, sr=self.sample_rate)[0]
        noisy_centroid = librosa.feature.spectral_centroid(y=noisy_audio, sr=self.sample_rate)[0]
        clean_centroid = librosa.feature.spectral_centroid(y=clean_audio, sr=self.sample_rate)[0]
        
        print(f"åŸå§‹éŸ³é¢‘é¢‘è°±è´¨å¿ƒ: {np.mean(orig_centroid):.1f} Hz")
        print(f"å¸¦å™ªéŸ³é¢‘é¢‘è°±è´¨å¿ƒ: {np.mean(noisy_centroid):.1f} Hz")
        print(f"æ¸…ç†åéŸ³é¢‘é¢‘è°±è´¨å¿ƒ: {np.mean(clean_centroid):.1f} Hz")
    
    def plot_noise_cleaning_comparison(self):
        """ç»˜åˆ¶å™ªå£°æ¸…ç†å¯¹æ¯”å›¾"""
        # ç¡®ä¿éŸ³é¢‘é•¿åº¦ä¸€è‡´ï¼ˆæˆªå–åˆ°æœ€çŸ­é•¿åº¦ï¼‰
        min_length = min(len(self.original_audio), len(self.noisy_audio), len(self.processed_audio))
        orig_audio = self.original_audio[:min_length]
        noisy_audio = self.noisy_audio[:min_length]
        clean_audio = self.processed_audio[:min_length]
        
        plt.figure(figsize=(18, 12))
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.family'] = ['DejaVu Sans', 'Arial', 'sans-serif', 'SimHei']
        plt.rcParams['axes.unicode_minus'] = False
        
        # 1. æ³¢å½¢å¯¹æ¯”
        plt.subplot(3, 3, 1)
        time_axis = np.arange(len(orig_audio)) / self.sample_rate
        plt.plot(time_axis, orig_audio, alpha=0.7, label='åŸå§‹')
        plt.xlabel('æ—¶é—´ (ç§’)')
        plt.ylabel('æŒ¯å¹…')
        plt.title('åŸå§‹éŸ³é¢‘æ³¢å½¢')
        plt.grid(True, alpha=0.3)
        
        plt.subplot(3, 3, 2)
        plt.plot(time_axis, noisy_audio, alpha=0.7, color='orange', label='å¸¦å™ª')
        plt.xlabel('æ—¶é—´ (ç§’)')
        plt.ylabel('æŒ¯å¹…')
        plt.title('å¸¦å™ªéŸ³é¢‘æ³¢å½¢')
        plt.grid(True, alpha=0.3)
        
        plt.subplot(3, 3, 3)
        plt.plot(time_axis, clean_audio, alpha=0.7, color='green', label='æ¸…ç†å')
        plt.xlabel('æ—¶é—´ (ç§’)')
        plt.ylabel('æŒ¯å¹…')
        plt.title('æ¸…ç†åéŸ³é¢‘æ³¢å½¢')
        plt.grid(True, alpha=0.3)
        
        # 2. é¢‘è°±å¯¹æ¯”
        plt.subplot(3, 3, 4)
        D_orig = librosa.amplitude_to_db(np.abs(librosa.stft(orig_audio)), ref=np.max)
        librosa.display.specshow(D_orig, sr=self.sample_rate, x_axis='time', y_axis='hz')
        plt.colorbar(format='%+2.0f dB')
        plt.title('åŸå§‹éŸ³é¢‘é¢‘è°±')
        plt.ylim(0, 8000)
        
        plt.subplot(3, 3, 5)
        D_noisy = librosa.amplitude_to_db(np.abs(librosa.stft(noisy_audio)), ref=np.max)
        librosa.display.specshow(D_noisy, sr=self.sample_rate, x_axis='time', y_axis='hz')
        plt.colorbar(format='%+2.0f dB')
        plt.title('å¸¦å™ªéŸ³é¢‘é¢‘è°±')
        plt.ylim(0, 8000)
        
        plt.subplot(3, 3, 6)
        D_clean = librosa.amplitude_to_db(np.abs(librosa.stft(clean_audio)), ref=np.max)
        librosa.display.specshow(D_clean, sr=self.sample_rate, x_axis='time', y_axis='hz')
        plt.colorbar(format='%+2.0f dB')
        plt.title('æ¸…ç†åéŸ³é¢‘é¢‘è°±')
        plt.ylim(0, 8000)
        
        # 3. é¢‘è°±åŒ…ç»œå¯¹æ¯”
        plt.subplot(3, 3, 7)
        f, Pxx_orig = signal.welch(orig_audio, self.sample_rate, nperseg=1024)
        f, Pxx_noisy = signal.welch(noisy_audio, self.sample_rate, nperseg=1024)
        f, Pxx_clean = signal.welch(clean_audio, self.sample_rate, nperseg=1024)
        
        plt.semilogy(f, Pxx_orig, label='åŸå§‹', alpha=0.8)
        plt.semilogy(f, Pxx_noisy, label='å¸¦å™ª', alpha=0.8)
        plt.semilogy(f, Pxx_clean, label='æ¸…ç†å', alpha=0.8)
        plt.xlim(0, 8000)
        plt.xlabel('é¢‘ç‡ (Hz)')
        plt.ylabel('åŠŸç‡è°±å¯†åº¦')
        plt.title('é¢‘è°±åŒ…ç»œå¯¹æ¯”')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # 4. å™ªå£°è°±å¯¹æ¯”
        plt.subplot(3, 3, 8)
        noise_spectrum = np.abs(librosa.stft(noisy_audio - orig_audio))
        librosa.display.specshow(librosa.amplitude_to_db(noise_spectrum, ref=np.max), 
                                sr=self.sample_rate, x_axis='time', y_axis='hz')
        plt.colorbar(format='%+2.0f dB')
        plt.title('åŸå§‹å™ªå£°è°±')
        plt.ylim(0, 8000)
        
        plt.subplot(3, 3, 9)
        clean_noise_spectrum = np.abs(librosa.stft(clean_audio - orig_audio))
        librosa.display.specshow(librosa.amplitude_to_db(clean_noise_spectrum, ref=np.max), 
                                sr=self.sample_rate, x_axis='time', y_axis='hz')
        plt.colorbar(format='%+2.0f dB')
        plt.title('æ®‹ç•™å™ªå£°è°±')
        plt.ylim(0, 8000)
        
        plt.tight_layout()
        plt.show()
    
    def save_noise_cleaning_files(self, prefix="noise_cleaning"):
        """ä¿å­˜å™ªå£°æ¸…ç†ç›¸å…³éŸ³é¢‘æ–‡ä»¶"""
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = "processed_audio"
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        # ç¡®ä¿æ–‡ä»¶ä¸ä¼šè¦†ç›–
        timestamp = np.random.randint(1000, 9999)
        orig_filename = os.path.join(output_dir, f"{prefix}_original_{timestamp}.wav")
        noisy_filename = os.path.join(output_dir, f"{prefix}_noisy_{timestamp}.wav")
        clean_filename = os.path.join(output_dir, f"{prefix}_cleaned_{timestamp}.wav")
        
        # ä¿å­˜æ‰€æœ‰éŸ³é¢‘
        sf.write(orig_filename, self.original_audio, self.sample_rate)
        sf.write(noisy_filename, self.noisy_audio, self.sample_rate)
        sf.write(clean_filename, self.processed_audio, self.sample_rate)
        
        print(f"åŸå§‹éŸ³é¢‘å·²ä¿å­˜: {orig_filename}")
        print(f"å¸¦å™ªéŸ³é¢‘å·²ä¿å­˜: {noisy_filename}")
        print(f"æ¸…ç†åéŸ³é¢‘å·²ä¿å­˜: {clean_filename}")
        print(f"æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶å·²ä¿å­˜åˆ° '{output_dir}' ç›®å½•ä¸­")
        
        return orig_filename, noisy_filename, clean_filename
    
    def play_audio_comparison(self):
        """æ’­æ”¾åŸå§‹å’Œå¤„ç†åçš„éŸ³é¢‘å¯¹æ¯”"""
        if self.original_audio is None or self.processed_audio is None:
            print("è¯·å…ˆåŠ è½½éŸ³é¢‘å¹¶åº”ç”¨å¤„ç†!")
            return
        
        print("\n" + "="*50)
        print("éŸ³é¢‘å¯¹æ¯”æ’­æ”¾")
        print("="*50)
        
        print("ğŸµ æ’­æ”¾åŸå§‹éŸ³é¢‘...")
        ipd.display(ipd.Audio(self.original_audio, rate=self.sample_rate))
        
        print("ğŸµ æ’­æ”¾å¤„ç†åçš„éŸ³é¢‘...")
        ipd.display(ipd.Audio(self.processed_audio, rate=self.sample_rate))
        
        # è®¡ç®—ä¸€äº›éŸ³é¢‘ç‰¹å¾ç”¨äºå¯¹æ¯”
        self.analyze_audio_differences()
    
    def analyze_audio_differences(self):
        """åˆ†æéŸ³é¢‘å·®å¼‚"""
        orig_rms = np.sqrt(np.mean(self.original_audio**2))
        proc_rms = np.sqrt(np.mean(self.processed_audio**2))
        
        # é¢‘è°±å¯¹æ¯”
        orig_spectrum = np.abs(librosa.stft(self.original_audio))
        proc_spectrum = np.abs(librosa.stft(self.processed_audio))
        
        print(f"\néŸ³é¢‘ç‰¹å¾å¯¹æ¯”:")
        print(f"åŸå§‹éŸ³é¢‘ RMS: {orig_rms:.4f}")
        print(f"å¤„ç†åéŸ³é¢‘ RMS: {proc_rms:.4f}")
        print(f"éŸ³é‡å˜åŒ–: {proc_rms/orig_rms:.2f}x")
        
        # é¢‘è°±è´¨å¿ƒå¯¹æ¯”
        orig_centroid = librosa.feature.spectral_centroid(y=self.original_audio, sr=self.sample_rate)[0]
        proc_centroid = librosa.feature.spectral_centroid(y=self.processed_audio, sr=self.sample_rate)[0]
        
        print(f"åŸå§‹éŸ³é¢‘é¢‘è°±è´¨å¿ƒ: {np.mean(orig_centroid):.1f} Hz")
        print(f"å¤„ç†åéŸ³é¢‘é¢‘è°±è´¨å¿ƒ: {np.mean(proc_centroid):.1f} Hz")
    
    def plot_comprehensive_comparison(self):
        """ç»˜åˆ¶å…¨é¢çš„éŸ³é¢‘å¯¹æ¯”å›¾"""
        if self.original_audio is None or self.processed_audio is None:
            print("è¯·å…ˆåŠ è½½éŸ³é¢‘å¹¶åº”ç”¨å¤„ç†!")
            return
        
        plt.figure(figsize=(16, 12))
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.family'] = ['DejaVu Sans', 'Arial', 'sans-serif', 'SimHei']
        plt.rcParams['axes.unicode_minus'] = False
        
        # 1. æ³¢å½¢å¯¹æ¯”
        plt.subplot(3, 2, 1)
        time_axis = np.arange(len(self.original_audio)) / self.sample_rate
        plt.plot(time_axis, self.original_audio, alpha=0.7, label='åŸå§‹')
        plt.xlabel('æ—¶é—´ (ç§’)')
        plt.ylabel('æŒ¯å¹…')
        plt.title('åŸå§‹éŸ³é¢‘æ³¢å½¢')
        plt.grid(True, alpha=0.3)
        
        plt.subplot(3, 2, 2)
        time_axis_proc = np.arange(len(self.processed_audio)) / self.sample_rate
        plt.plot(time_axis_proc, self.processed_audio, alpha=0.7, color='red', label='å¤„ç†å')
        plt.xlabel('æ—¶é—´ (ç§’)')
        plt.ylabel('æŒ¯å¹…')
        plt.title('å¤„ç†åéŸ³é¢‘æ³¢å½¢')
        plt.grid(True, alpha=0.3)
        
        # 2. é¢‘è°±å¯¹æ¯”
        plt.subplot(3, 2, 3)
        D_orig = librosa.amplitude_to_db(np.abs(librosa.stft(self.original_audio)), ref=np.max)
        librosa.display.specshow(D_orig, sr=self.sample_rate, x_axis='time', y_axis='hz')
        plt.colorbar(format='%+2.0f dB')
        plt.title('åŸå§‹éŸ³é¢‘é¢‘è°±')
        plt.ylim(0, 8000)
        
        plt.subplot(3, 2, 4)
        D_proc = librosa.amplitude_to_db(np.abs(librosa.stft(self.processed_audio)), ref=np.max)
        librosa.display.specshow(D_proc, sr=self.sample_rate, x_axis='time', y_axis='hz')
        plt.colorbar(format='%+2.0f dB')
        plt.title('å¤„ç†åéŸ³é¢‘é¢‘è°±')
        plt.ylim(0, 8000)
        
        # 3. é¢‘è°±åŒ…ç»œå¯¹æ¯”
        plt.subplot(3, 2, 5)
        f, Pxx_orig = signal.welch(self.original_audio, self.sample_rate, nperseg=1024)
        f, Pxx_proc = signal.welch(self.processed_audio, self.sample_rate, nperseg=1024)
        
        plt.semilogy(f, Pxx_orig, label='åŸå§‹', alpha=0.8)
        plt.semilogy(f, Pxx_proc, label='å¤„ç†å', alpha=0.8)
        plt.xlim(0, 8000)
        plt.xlabel('é¢‘ç‡ (Hz)')
        plt.ylabel('åŠŸç‡è°±å¯†åº¦')
        plt.title('é¢‘è°±åŒ…ç»œå¯¹æ¯”')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # 4. MFCCç‰¹å¾å¯¹æ¯”ï¼ˆåˆ†åˆ«æ˜¾ç¤ºï¼‰
        plt.subplot(3, 2, 6)
        mfcc_orig = librosa.feature.mfcc(y=self.original_audio, sr=self.sample_rate, n_mfcc=13)
        librosa.display.specshow(mfcc_orig, sr=self.sample_rate, x_axis='time')
        plt.colorbar()
        plt.title('åŸå§‹éŸ³é¢‘MFCC')
        
        plt.tight_layout()
        plt.show()
    
    def save_audio_files(self, prefix="audio_comparison"):
        """ä¿å­˜éŸ³é¢‘æ–‡ä»¶"""
        if self.original_audio is None or self.processed_audio is None:
            print("è¯·å…ˆåŠ è½½éŸ³é¢‘å¹¶åº”ç”¨å¤„ç†!")
            return
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = "processed_audio"
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        # ç¡®ä¿æ–‡ä»¶ä¸ä¼šè¦†ç›–
        timestamp = np.random.randint(1000, 9999)
        orig_filename = os.path.join(output_dir, f"{prefix}_original_{timestamp}.wav")
        proc_filename = os.path.join(output_dir, f"{prefix}_processed_{timestamp}.wav")
        
        # ä¿å­˜åŸå§‹éŸ³é¢‘
        sf.write(orig_filename, self.original_audio, self.sample_rate)
        print(f"åŸå§‹éŸ³é¢‘å·²ä¿å­˜: {orig_filename}")
        
        # ä¿å­˜å¤„ç†åçš„éŸ³é¢‘
        sf.write(proc_filename, self.processed_audio, self.sample_rate)
        print(f"å¤„ç†åéŸ³é¢‘å·²ä¿å­˜: {proc_filename}")
        
        print(f"æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶å·²ä¿å­˜åˆ° '{output_dir}' ç›®å½•ä¸­")
        return orig_filename, proc_filename
    
    def interactive_demo(self):
        """äº¤äº’å¼æ¼”ç¤º"""
        print("ğŸµ éŸ³é¢‘å¤„ç†æ¼”ç¤ºç¨‹åº")
        print("="*50)
        
        # é€‰æ‹©éŸ³é¢‘æ¥æº
        print("é€‰æ‹©éŸ³é¢‘æ¥æº:")
        print("1. ä»URLä¸‹è½½éŸ³é¢‘")
        print("2. ä½¿ç”¨å†…ç½®ç¤ºä¾‹éŸ³é¢‘")
        print("3. å®æ—¶å½•éŸ³")
        print("4. ç”Ÿæˆæµ‹è¯•éŸ³é¢‘")
        
        source_choice = input("è¯·è¾“å…¥é€‰æ‹© (1-4): ").strip()
        
        if source_choice == "1":
            url = input("è¯·è¾“å…¥éŸ³é¢‘URL: ").strip()
            self.download_audio_from_url(url)
        elif source_choice == "2":
            self.load_example_audio()
        elif source_choice == "3":
            duration = float(input("è¯·è¾“å…¥å½•éŸ³æ—¶é•¿ (ç§’): ").strip() or "5")
            self.record_audio(duration=duration)
        else:
            self.generate_test_audio()
        
        # é€‰æ‹©å¤„ç†æ•ˆæœ
        print("\né€‰æ‹©å¤„ç†æ•ˆæœ:")
        print("1. æˆå‰§æ€§å˜åŒ– (æ¨è - éŸ³é«˜å˜æ¢+æ—¶é—´æ‹‰ä¼¸+å¤±çœŸ+æ··å“)")
        print("2. éŸ³é«˜å˜æ¢")
        print("3. æ—¶é—´æ‹‰ä¼¸")
        print("4. ä½é€šæ»¤æ³¢")
        print("5. é«˜é€šæ»¤æ³¢")
        print("6. å¤±çœŸæ•ˆæœ")
        print("7. æ··å“æ•ˆæœ")
        
        effect_choice = input("è¯·è¾“å…¥é€‰æ‹© (1-7): ").strip()
        
        if effect_choice == "1":
            self.processed_audio = self.create_dramatic_effect(self.original_audio)
        elif effect_choice == "2":
            steps = int(input("è¯·è¾“å…¥éŸ³é«˜å˜åŒ–åŠéŸ³æ•° (æ­£æ•°æé«˜, è´Ÿæ•°é™ä½): ").strip() or "4")
            self.processed_audio = self.apply_pitch_shift(self.original_audio, n_steps=steps)
        elif effect_choice == "3":
            rate = float(input("è¯·è¾“å…¥æ—¶é—´æ‹‰ä¼¸æ¯”ç‡ (>1åŠ é€Ÿ, <1å‡é€Ÿ): ").strip() or "1.5")
            self.processed_audio = self.apply_time_stretch(self.original_audio, rate=rate)
        elif effect_choice == "4":
            cutoff = int(input("è¯·è¾“å…¥ä½é€šæ»¤æ³¢æˆªæ­¢é¢‘ç‡ (Hz): ").strip() or "1000")
            self.processed_audio = self.apply_lowpass_filter(self.original_audio, cutoff_freq=cutoff)
        elif effect_choice == "5":
            cutoff = int(input("è¯·è¾“å…¥é«˜é€šæ»¤æ³¢æˆªæ­¢é¢‘ç‡ (Hz): ").strip() or "2000")
            self.processed_audio = self.apply_highpass_filter(self.original_audio, cutoff_freq=cutoff)
        elif effect_choice == "6":
            gain = float(input("è¯·è¾“å…¥å¤±çœŸå¢ç›Š: ").strip() or "5.0")
            self.processed_audio = self.apply_distortion(self.original_audio, gain=gain)
        elif effect_choice == "7":
            delay = float(input("è¯·è¾“å…¥æ··å“å»¶è¿Ÿ (ç§’): ").strip() or "0.1")
            decay = float(input("è¯·è¾“å…¥æ··å“è¡°å‡: ").strip() or "0.5")
            self.processed_audio = self.apply_reverb(self.original_audio, delay=delay, decay=decay)
        else:
            print("ä½¿ç”¨é»˜è®¤æˆå‰§æ€§å˜åŒ–æ•ˆæœ")
            self.processed_audio = self.create_dramatic_effect(self.original_audio)
        
        # æ˜¾ç¤ºç»“æœ
        print("\n" + "="*50)
        print("å¤„ç†å®Œæˆ!")
        print("="*50)
        
        # æ’­æ”¾å¯¹æ¯”
        self.play_audio_comparison()
        
        # æ˜¾ç¤ºå›¾è¡¨
        print("\nç”Ÿæˆå¯¹æ¯”å›¾è¡¨...")
        self.plot_comprehensive_comparison()
        
        # ä¿å­˜é€‰é¡¹
        save_choice = input("\næ˜¯å¦ä¿å­˜éŸ³é¢‘æ–‡ä»¶? (y/n): ").strip().lower()
        if save_choice == 'y':
            self.save_audio_files()
        
        print("\næ¼”ç¤ºå®Œæˆ!")

# ç¤ºä¾‹URLåˆ—è¡¨ï¼ˆå¯ä»¥ä½¿ç”¨çš„éŸ³é¢‘èµ„æºï¼‰
EXAMPLE_URLS = [
    "https://www2.cs.uic.edu/~i101/SoundFiles/StarWars60.wav",
    "https://www2.cs.uic.edu/~i101/SoundFiles/ImperialMarch60.wav",
    "https://www2.cs.uic.edu/~i101/SoundFiles/CantinaBand60.wav",
    "https://www2.cs.uic.edu/~i101/SoundFiles/preamble10.wav"
]

def quick_demo_with_example_url():
    """ä½¿ç”¨ç¤ºä¾‹URLå¿«é€Ÿæ¼”ç¤º"""
    demo = AudioProcessingDemo()
    
    print("ğŸµ å¿«é€ŸéŸ³é¢‘å¤„ç†æ¼”ç¤º")
    print("="*50)
    print("å¯ç”¨çš„ç¤ºä¾‹éŸ³é¢‘:")
    for i, url in enumerate(EXAMPLE_URLS, 1):
        filename = os.path.basename(urlparse(url).path)
        print(f"{i}. {filename}")
    
    choice = int(input("è¯·é€‰æ‹©éŸ³é¢‘ (1-4): ").strip() or "1")
    url = EXAMPLE_URLS[choice-1]
    
    # ä¸‹è½½å¹¶å¤„ç†éŸ³é¢‘
    demo.download_audio_from_url(url)
    demo.processed_audio = demo.create_dramatic_effect(demo.original_audio)
    
    # æ’­æ”¾å¯¹æ¯”
    demo.play_audio_comparison()
    demo.plot_comprehensive_comparison()
    
    # ä¿å­˜æ–‡ä»¶
    demo.save_audio_files()

def noise_cleaning_demo():
    """å™ªå£°æ¸…ç†æ¼”ç¤º"""
    demo = AudioProcessingDemo()
    
    print("ğŸµ å™ªå£°æ¸…ç†å’Œè¯­éŸ³å¢å¼ºæ¼”ç¤º")
    print("="*50)
    print("å¯ç”¨çš„ç¤ºä¾‹éŸ³é¢‘:")
    for i, url in enumerate(EXAMPLE_URLS, 1):
        filename = os.path.basename(urlparse(url).path)
        print(f"{i}. {filename}")
    
    choice = int(input("è¯·é€‰æ‹©éŸ³é¢‘ (1-4): ").strip() or "1")
    url = EXAMPLE_URLS[choice-1]
    
    # ä¸‹è½½éŸ³é¢‘
    demo.download_audio_from_url(url)
    
    # æ¼”ç¤ºå™ªå£°æ¸…ç†æ•ˆæœ
    demo.demonstrate_noise_cleaning()

# ä¸»ç¨‹åº
if __name__ == "__main__":
    # å®‰è£…æ‰€éœ€åº“çš„å‘½ä»¤:
    # pip install numpy matplotlib librosa sounddevice soundfile scipy requests ipython
    
    print("éŸ³é¢‘å¤„ç†æ¼”ç¤ºç¨‹åº")
    print("="*50)
    print("åŠŸèƒ½ç‰¹ç‚¹:")
    print("â€¢ æ”¯æŒä»URLä¸‹è½½éŸ³é¢‘")
    print("â€¢ å¤šç§éŸ³é¢‘å¤„ç†æ•ˆæœ")
    print("â€¢ å¬è§‰æ˜æ˜¾ä¸åŒçš„å‰åå¯¹æ¯”")
    print("â€¢ å¯è§†åŒ–åˆ†æ")
    print("â€¢ éŸ³é¢‘æ–‡ä»¶ä¿å­˜")
    print("="*50)
    
    demo = AudioProcessingDemo()
    
    # é€‰æ‹©æ¼”ç¤ºæ¨¡å¼
    print("é€‰æ‹©æ¼”ç¤ºæ¨¡å¼:")
    print("1. äº¤äº’å¼æ¼”ç¤º (æ¨è)")
    print("2. å¿«é€Ÿç¤ºä¾‹æ¼”ç¤º")
    print("3. å™ªå£°æ¸…ç†æ¼”ç¤º")
    print("4. è‡ªå®šä¹‰å¤„ç†")
    
    mode_choice = input("è¯·è¾“å…¥é€‰æ‹© (1-4): ").strip() or "1"
    
    if mode_choice == "1":
        demo.interactive_demo()
    elif mode_choice == "2":
        quick_demo_with_example_url()
    elif mode_choice == "3":
        noise_cleaning_demo()
    else:
        # è‡ªå®šä¹‰å¤„ç†æ¨¡å¼
        print("è‡ªå®šä¹‰å¤„ç†æ¨¡å¼")
        url = input("è¯·è¾“å…¥éŸ³é¢‘URL (ç•™ç©ºä½¿ç”¨ç¤ºä¾‹éŸ³é¢‘): ").strip()
        
        if url:
            demo.download_audio_from_url(url)
        else:
            demo.load_example_audio()
        
        # åº”ç”¨æˆå‰§æ€§æ•ˆæœ
        demo.processed_audio = demo.create_dramatic_effect(demo.original_audio)
        
        # æ˜¾ç¤ºç»“æœ
        demo.play_audio_comparison()
        demo.plot_comprehensive_comparison()
        
        save_choice = input("æ˜¯å¦ä¿å­˜éŸ³é¢‘æ–‡ä»¶? (y/n): ").strip().lower()
        if save_choice == 'y':
            demo.save_audio_files()
    
    print("\nç¨‹åºæ‰§è¡Œå®Œæˆ!")
