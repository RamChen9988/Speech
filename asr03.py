# å®Œå…¨ç¦»çº¿çš„è¯­éŸ³è¯†åˆ«æ¼”ç¤º - å›½å†…ç½‘ç»œç¯å¢ƒä¸‹å¯ç¨³å®šè¿è¡Œ
import os
import wave
import numpy as np
from vosk import Model, KaldiRecognizer
import pyaudio
import threading
import time
import subprocess
import sys

def install_offline_dependencies():
    """å®‰è£…ç¦»çº¿è¯­éŸ³è¯†åˆ«æ‰€éœ€çš„ä¾èµ–"""
    print("ğŸ”§ å®‰è£…ç¦»çº¿è¯­éŸ³è¯†åˆ«ç»„ä»¶...")
    
    packages = [
        "vosk",
        "pyaudio",
        "numpy"
    ]
    
    for package in packages:
        try:
            __import__(package.replace("-", "_"))
            print(f"âœ… {package} å·²å®‰è£…")
        except ImportError:
            print(f"ğŸ“¥ æ­£åœ¨å®‰è£… {package}...")
            subprocess.check_call([sys.executable, "-m", "pip", "install", package])
            print(f"âœ… {package} å®‰è£…å®Œæˆ")

def download_vosk_model():
    """ä¸‹è½½Voskä¸­æ–‡è¯­éŸ³è¯†åˆ«æ¨¡å‹"""
    model_path = "vosk-model-cn-0.22"
    model_url = "https://alphacephei.com/vosk/models/vosk-model-cn-0.22.zip"
    
    if os.path.exists(model_path):
        print(f"âœ… Voskä¸­æ–‡æ¨¡å‹å·²å­˜åœ¨: {model_path}")
        return model_path
    
    print("ğŸ“¥ æ­£åœ¨ä¸‹è½½ä¸­æ–‡è¯­éŸ³è¯†åˆ«æ¨¡å‹(çº¦1.8GB)...")
    print("ğŸ’¡ é¦–æ¬¡ä¸‹è½½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")
    
    try:
        import urllib.request
        import zipfile
        
        # ä¸‹è½½æ¨¡å‹æ–‡ä»¶
        zip_path = "vosk-model-cn-0.22.zip"
        urllib.request.urlretrieve(model_url, zip_path)
        
        # è§£å‹æ¨¡å‹
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(".")
        
        # åˆ é™¤å‹ç¼©åŒ…
        os.remove(zip_path)
        print("âœ… ä¸­æ–‡è¯­éŸ³æ¨¡å‹ä¸‹è½½å®Œæˆï¼")
        return model_path
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
        print("ğŸ’¡ è¯·æ‰‹åŠ¨ä¸‹è½½: https://alphacephei.com/vosk/models")
        print("ğŸ’¡ æˆ–ä½¿ç”¨å¤‡ç”¨çš„å°æ¨¡å‹")
        return None

def create_sample_audio():
    """åˆ›å»ºç¤ºä¾‹éŸ³é¢‘æ–‡ä»¶ç”¨äºæ¼”ç¤º"""
    print("ğŸµ åˆ›å»ºç¤ºä¾‹éŸ³é¢‘æ–‡ä»¶...")
    
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„æ­£å¼¦æ³¢ä½œä¸ºç¤ºä¾‹éŸ³é¢‘
    sample_rate = 16000
    duration = 3  # 3ç§’
    t = np.linspace(0, duration, int(sample_rate * duration))
    
    # ç”Ÿæˆ440Hzçš„æ­£å¼¦æ³¢ï¼ˆA4éŸ³ç¬¦ï¼‰
    audio_data = np.sin(2 * np.pi * 440 * t) * 0.5
    
    # ä¿å­˜ä¸ºWAVæ–‡ä»¶
    with wave.open("sample_audio.wav", 'wb') as wf:
        wf.setnchannels(1)  # å•å£°é“
        wf.setsampwidth(2)  # 16ä½
        wf.setframerate(sample_rate)
        wf.writeframes((audio_data * 32767).astype(np.int16).tobytes())
    
    print("âœ… ç¤ºä¾‹éŸ³é¢‘åˆ›å»ºå®Œæˆ")
    return "sample_audio.wav"

def offline_speech_recognition(model_path):
    """
    ç¦»çº¿å®æ—¶è¯­éŸ³è¯†åˆ«
    å®Œå…¨åœ¨æœ¬åœ°è¿è¡Œï¼Œæ— éœ€ç½‘ç»œè¿æ¥
    """
    if not model_path or not os.path.exists(model_path):
        print("âŒ è¯­éŸ³æ¨¡å‹ä¸å­˜åœ¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
        return simulate_recognition()
    
    print("ğŸ¤ åˆå§‹åŒ–ç¦»çº¿è¯­éŸ³è¯†åˆ«ç³»ç»Ÿ...")
    
    # åŠ è½½Voskæ¨¡å‹
    model = Model(model_path)
    recognizer = KaldiRecognizer(model, 16000)
    
    # åˆå§‹åŒ–éŸ³é¢‘è¾“å…¥
    audio = pyaudio.PyAudio()
    stream = audio.open(
        format=pyaudio.paInt16,
        channels=1,
        rate=16000,
        input=True,
        frames_per_buffer=4096
    )
    
    print("ğŸ”Š ç¦»çº¿è¯­éŸ³è¯†åˆ«å·²å¯åŠ¨!")
    print("ğŸ’¡ è¯·å¯¹ç€éº¦å…‹é£è¯´è¯...")
    print("â¹ï¸ æŒ‰ Ctrl+C åœæ­¢è¯†åˆ«")
    
    try:
        while True:
            # è¯»å–éŸ³é¢‘æ•°æ®
            data = stream.read(4096, exception_on_overflow=False)
            
            if recognizer.AcceptWaveform(data):
                # è·å–è¯†åˆ«ç»“æœ
                result = recognizer.Result()
                result_json = eval(result)
                
                if 'text' in result_json and result_json['text']:
                    recognized_text = result_json['text']
                    print(f"âœ… è¯†åˆ«ç»“æœ: {recognized_text}")
                    
                    # æ‰§è¡Œç›¸åº”çš„å‘½ä»¤
                    if not execute_offline_command(recognized_text):
                        break
            
            # å®æ—¶æ˜¾ç¤ºéƒ¨åˆ†ç»“æœ
            partial_result = recognizer.PartialResult()
            partial_json = eval(partial_result)
            if 'partial' in partial_json and partial_json['partial']:
                print(f"ğŸ” å®æ—¶è¯†åˆ«: {partial_json['partial']}", end='\r')
                
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ åœæ­¢è¯­éŸ³è¯†åˆ«")
    finally:
        stream.stop_stream()
        stream.close()
        audio.terminate()

def simulate_recognition():
    """
    æ¨¡æ‹Ÿè¯­éŸ³è¯†åˆ«ï¼ˆåœ¨æ²¡æœ‰çœŸå®æ¨¡å‹æ—¶ä½¿ç”¨ï¼‰
    """
    print("ğŸ­ æ¨¡æ‹Ÿè¯­éŸ³è¯†åˆ«æ¨¡å¼ï¼ˆä½¿ç”¨é”®ç›˜è¾“å…¥æµ‹è¯•ï¼‰")
    print("ğŸ’¡ è¯·è¾“å…¥æŒ‡ä»¤æ¥æ¨¡æ‹Ÿè¯­éŸ³è¾“å…¥:")
    
    demo_commands = [
        "æ‰“å¼€ç¯å…‰",
        "æ’­æ”¾éŸ³ä¹", 
        "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·",
        "å¯¼èˆªåˆ°å­¦æ ¡",
        "é€€å‡º"
    ]
    
    for i, cmd in enumerate(demo_commands, 1):
        print(f"{i}. {cmd}")
    
    while True:
        try:
            choice = input("\nè¯·é€‰æ‹©æŒ‡ä»¤ç¼–å· (1-5): ").strip()
            if choice.isdigit() and 1 <= int(choice) <= 5:
                command_text = demo_commands[int(choice) - 1]
                print(f"ğŸ—£ï¸ æ¨¡æ‹Ÿè¯­éŸ³è¾“å…¥: {command_text}")
                
                if not execute_offline_command(command_text):
                    break
            else:
                print("âŒ è¯·è¾“å…¥æœ‰æ•ˆç¼–å·")
        except KeyboardInterrupt:
            print("\nğŸ‘‹ é€€å‡ºæ¨¡æ‹Ÿæ¨¡å¼")
            break

def execute_offline_command(command_text):
    """
    æ‰§è¡Œç¦»çº¿è¯†åˆ«åˆ°çš„å‘½ä»¤
    """
    command = command_text.lower()
    
    print(f"ğŸ¤– åˆ†ææŒ‡ä»¤: {command}")
    
    # æ™ºèƒ½å®¶å±…æ§åˆ¶
    if any(word in command for word in ['æ‰“å¼€', 'å¼€å¯', 'å¯åŠ¨']):
        if 'ç¯' in command:
            print("ğŸ’¡ æ‰§è¡Œ: æ‰“å¼€ç¯å…‰")
            print("âœ¨ å®¢å…ç¯å…‰å·²å¼€å¯ - [æ™ºèƒ½å®¶å±…ç³»ç»Ÿå“åº”]")
        elif 'ç©ºè°ƒ' in command:
            print("â„ï¸ æ‰§è¡Œ: æ‰“å¼€ç©ºè°ƒ")
            print("ğŸŒ¡ï¸ ç©ºè°ƒå·²å¯åŠ¨ï¼Œè®¾å®šæ¸©åº¦24â„ƒ - [IoTè®¾å¤‡å“åº”]")
        elif 'éŸ³ä¹' in command:
            print("ğŸµ æ‰§è¡Œ: æ’­æ”¾éŸ³ä¹")
            print("ğŸ¶ æ­£åœ¨æ’­æ”¾æ¨èæ­Œå•... - [åª’ä½“ç³»ç»Ÿå“åº”]")
    
    # æŸ¥è¯¢åŠŸèƒ½
    elif any(word in command for word in ['å¤©æ°”', 'æ¸©åº¦']):
        print("ğŸŒ¤ï¸ æ‰§è¡Œ: æŸ¥è¯¢å¤©æ°”")
        print("ğŸ“Š ä»Šå¤©æ™´è½¬å¤šäº‘ï¼Œ25â„ƒï¼Œé€‚å®œå¤–å‡º - [å¤©æ°”æœåŠ¡å“åº”]")
    
    # å¯¼èˆªåŠŸèƒ½
    elif any(word in command for word in ['å¯¼èˆª', 'å»', 'åˆ°']):
        print("ğŸ—ºï¸ æ‰§è¡Œ: è·¯å¾„è§„åˆ’")
        print("ğŸ“ å·²ä¸ºæ‚¨è§„åˆ’æœ€ä¼˜è·¯çº¿ï¼Œé¢„è®¡ç”¨æ—¶15åˆ†é’Ÿ - [å¯¼èˆªç³»ç»Ÿå“åº”]")
    
    # ç³»ç»Ÿæ§åˆ¶
    elif 'é€€å‡º' in command or 'ç»“æŸ' in command:
        print("ğŸ‘‹ é€€å‡ºè¯­éŸ³è¯†åˆ«ç³»ç»Ÿ")
        return False
    elif 'ä½ å¥½' in command:
        print("ğŸ‘‹ ä½ å¥½ï¼æˆ‘æ˜¯ç¦»çº¿è¯­éŸ³åŠ©æ‰‹")
    elif 'è°¢è°¢' in command:
        print("ğŸ˜Š ä¸å®¢æ°”ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡")
    else:
        print("ğŸ’­ æŒ‡ä»¤å·²æ”¶åˆ°ï¼Œæ­£åœ¨å¤„ç†...")
    
    return True

def demonstrate_asr_workflow():
    """
    æ¼”ç¤ºè¯­éŸ³è¯†åˆ«çš„å®Œæ•´å·¥ä½œæµç¨‹
    """
    print("\n" + "="*60)
    print("ğŸ”¬ è¯­éŸ³è¯†åˆ«æŠ€æœ¯æµç¨‹è¯¦è§£")
    print("="*60)
    
    steps = [
        {
            "æ­¥éª¤": "1. éŸ³é¢‘é‡‡é›†",
            "æŠ€æœ¯": "éº¦å…‹é£ â†’ PCMæ•°æ®",
            "ç±»æ¯”": "ç”¨è€³æœµå¬å£°éŸ³"
        },
        {
            "æ­¥éª¤": "2. é¢„å¤„ç†", 
            "æŠ€æœ¯": "é™å™ªã€åˆ†å¸§ã€åŠ çª—",
            "ç±»æ¯”": "è¿‡æ»¤èƒŒæ™¯å™ªéŸ³"
        },
        {
            "æ­¥éª¤": "3. ç‰¹å¾æå–",
            "æŠ€æœ¯": "MFCCç‰¹å¾å‘é‡", 
            "ç±»æ¯”": "æå–å£°éŸ³æŒ‡çº¹"
        },
        {
            "æ­¥éª¤": "4. å£°å­¦æ¨¡å‹",
            "æŠ€æœ¯": "DNN/HMMè¯†åˆ«éŸ³ç´ ",
            "ç±»æ¯”": "è¯†åˆ«å‘éŸ³å•ä½"
        },
        {
            "æ­¥éª¤": "5. è¯­è¨€æ¨¡å‹", 
            "æŠ€æœ¯": "N-gram/Transformer",
            "ç±»æ¯”": "ç†è§£è¯­è¨€è§„å¾‹"
        },
        {
            "æ­¥éª¤": "6. è§£ç è¾“å‡º",
            "æŠ€æœ¯": "ç»´ç‰¹æ¯”ç®—æ³•",
            "ç±»æ¯”": "ç»„åˆæˆå®Œæ•´å¥å­"
        }
    ]
    
    for step in steps:
        print(f"\n{step['æ­¥éª¤']}: {step['æŠ€æœ¯']}")
        print(f"   ğŸ¯ {step['ç±»æ¯”']}")

def file_based_recognition(model_path, audio_file=None):
    """
    åŸºäºæ–‡ä»¶çš„è¯­éŸ³è¯†åˆ«æ¼”ç¤º
    """
    if not audio_file:
        audio_file = create_sample_audio()
        print("ğŸ’¡ ä½¿ç”¨ç”Ÿæˆçš„ç¤ºä¾‹éŸ³é¢‘è¿›è¡Œè¯†åˆ«æ¼”ç¤º")
    
    if not os.path.exists(audio_file):
        print(f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_file}")
        return
    
    print(f"ğŸ“ è¯†åˆ«éŸ³é¢‘æ–‡ä»¶: {audio_file}")
    
    if not model_path or not os.path.exists(model_path):
        print("ğŸ”Š æ¨¡æ‹Ÿæ–‡ä»¶è¯†åˆ«ç»“æœ: 'è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•éŸ³é¢‘æ–‡ä»¶'")
        return
    
    try:
        # ä½¿ç”¨Voskè¿›è¡Œæ–‡ä»¶è¯†åˆ«
        model = Model(model_path)
        wf = wave.open(audio_file, 'rb')
        
        if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != "NONE":
            print("âŒ éŸ³é¢‘æ ¼å¼ä¸æ”¯æŒï¼Œéœ€è¦å•å£°é“16ä½PCMæ ¼å¼")
            return
        
        recognizer = KaldiRecognizer(model, wf.getframerate())
        
        print("ğŸ” æ­£åœ¨è¯†åˆ«éŸ³é¢‘æ–‡ä»¶å†…å®¹...")
        while True:
            data = wf.readframes(4096)
            if len(data) == 0:
                break
            recognizer.AcceptWaveform(data)
        
        result = recognizer.FinalResult()
        result_json = eval(result)
        
        if 'text' in result_json:
            print(f"âœ… æ–‡ä»¶è¯†åˆ«ç»“æœ: {result_json['text']}")
        else:
            print("âŒ æœªèƒ½è¯†åˆ«å‡ºæœ‰æ•ˆå†…å®¹")
            
    except Exception as e:
        print(f"âŒ æ–‡ä»¶è¯†åˆ«å¤±è´¥: {e}")

# ä¸»ç¨‹åº
if __name__ == "__main__":
    print("ğŸ¯ ç¦»çº¿è¯­éŸ³è¯†åˆ«ç³»ç»Ÿæ¼”ç¤º")
    print("=" * 50)
    print("ğŸ’¡ ç‰¹ç‚¹: å®Œå…¨æœ¬åœ°è¿è¡Œ Â· æ— éœ€ç½‘ç»œ Â· ä¿æŠ¤éšç§")
    
    # å®‰è£…ä¾èµ–
    install_offline_dependencies()
    
    # æŠ€æœ¯æµç¨‹æ¼”ç¤º
    demonstrate_asr_workflow()
    
    print("\n" + "="*50)
    print("ğŸš€ é€‰æ‹©è¯†åˆ«æ¨¡å¼:")
    print("1. å®æ—¶è¯­éŸ³è¯†åˆ«ï¼ˆéœ€è¦éº¦å…‹é£ï¼‰")
    print("2. æ–‡ä»¶è¯­éŸ³è¯†åˆ«") 
    print("3. æ¨¡æ‹Ÿæ¼”ç¤ºæ¨¡å¼ï¼ˆæ— éœ€éº¦å…‹é£ï¼‰")
    print("4. ä¸‹è½½è¯­éŸ³æ¨¡å‹")
    
    try:
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-4): ").strip()
        
        model_path = None
        if choice in ["1", "2"]:
            print("\nğŸ“¥ å‡†å¤‡è¯­éŸ³è¯†åˆ«æ¨¡å‹...")
            model_path = download_vosk_model()
        
        if choice == "1":
            print("\nğŸ¤ å¯åŠ¨å®æ—¶è¯­éŸ³è¯†åˆ«...")
            offline_speech_recognition(model_path)
        elif choice == "2":
            file_path = input("è¯·è¾“å…¥éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆç•™ç©ºä½¿ç”¨ç¤ºä¾‹ï¼‰: ").strip()
            file_based_recognition(model_path, file_path if file_path else None)
        elif choice == "3":
            simulate_recognition()
        elif choice == "4":
            download_vosk_model()
            print("âœ… æ¨¡å‹ä¸‹è½½å®Œæˆï¼Œè¯·é‡æ–°è¿è¡Œç¨‹åºä½¿ç”¨")
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")
            
    except Exception as e:
        print(f"âŒ ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
        print("ğŸ’¡ æç¤º: è¯·æ£€æŸ¥éº¦å…‹é£æƒé™å’ŒéŸ³é¢‘è®¾å¤‡")
    
    print("\n" + "="*50)
    print("ğŸ“ æ•™å­¦è¦ç‚¹æ€»ç»“:")
    print("   - Vosk: å¼€æºç¦»çº¿è¯­éŸ³è¯†åˆ«å·¥å…·åŒ…")
    print("   - å£°å­¦æ¨¡å‹: å°†å£°éŸ³ç‰¹å¾æ˜ å°„åˆ°éŸ³ç´ ") 
    print("   - è¯­è¨€æ¨¡å‹: æ ¹æ®ä¸Šä¸‹æ–‡é¢„æµ‹æœ€å¯èƒ½çš„æ–‡æœ¬")
    print("   - å®æ—¶è¯†åˆ«: æµå¼å¤„ç†ï¼Œä½å»¶è¿Ÿå“åº”")
    print("ğŸ‰ ç¦»çº¿è¯­éŸ³è¯†åˆ«ä½“éªŒå®Œæˆï¼")